---
title: "DM Group 19 LDA and QDA Analysis"
author: "Mina Narayanan"
date: "5/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(ISLR)
library(MASS)
library(klaR) 
library(knitr)
library(glmnet)
library(gam)
library(plyr)
library(reshape)
library(boot)
library(survival)
library(ggfortify)
```

Summary:

We seek to explore predictors of recidivism on the Broward County Population by conducting the following analysis:
(1) Construct an RAI for predicting two-year recidivism on the Broward County population. 
(2) Construct an RAI for predicting two-year violent recidivism on the Broward County population
(3) Determine whether each RAI is equally predictive across race, age, and gender
(4) Compare the performance of our RAIs to COMPAS

This file creates four models: (1) LDA model to classify people who have committed a criminal offense in Broward County as likely to recidivate or not, (2) LDA model to classify people who have committed a criminal offense in Broward County as likely to violently recidivate or not, (3) QDA model to classify people who have committed a criminal offense in Broward County as likely to recidivate or not, and (4) QDA model to classify people who have committed a criminal offense in Broward County as likely to violently recidivate or not. These four models encompass steps 1 and 2 of our analysis above.

The nonviolent LDA model has an accuracy of approximately 67%, whereas the violent LDA model has an accuracy of about 88%. The nonviolent QDA model has an accuracy of approximately 63%, whereas the violent QDA model has an accuracy of about 86%.

Neither the LDA nor the QDA models had higher concordance scores than the COMPAS model. The nonviolent LDA model had a concordance of 62.3% and the nonviolent QDA model had a concordance of 58.9%, whereas COMPAS had a concordance of 63.6% for nonviolent recidivism. The violent LDA model had a concordance of 50.2% and the violent QDA model had a concordance of 52.7%, whereas COMPAS had a concordance of 65.1% for violent recidivism. Therefore, we chose not to include the QDA and LDA models in our analysis for steps 3 and 4.  


# Read in Compas Data

Subset of columns used in original analysis are:
raw_data, age, c_charge_degree, race, age_cat, score_text, sex, priors_count, days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out

```{r}
# Read in compas data
raw_data <- read.csv("./compas-scores-two-years.csv")
nrow(raw_data)

compas_non_violent <- raw_data %>% 
  filter(days_b_screening_arrest <= 30) %>%
  filter(days_b_screening_arrest >= -30) %>%
  filter(is_recid != -1) %>%
  filter(c_charge_degree != "O") %>%
  filter(score_text != 'N/A')
nrow(compas_non_violent)

compas_non_violent <- mutate(compas_non_violent, crime_factor = factor(c_charge_degree)) %>%
      mutate(age_factor = as.factor(age_cat)) %>%
      within(age_factor <- relevel(age_factor, ref = 1)) %>%
      mutate(race_factor = factor(race)) %>%
      within(race_factor <- relevel(race_factor, ref = 3)) %>%
      mutate(gender_factor = factor(sex, labels= c("Female","Male"))) %>%
      within(gender_factor <- relevel(gender_factor, ref = 2)) %>%
      mutate(score_factor = factor(score_text != "Low", labels = c("LowScore","HighScore")))

# Read in cox proportional hazards data
cox_parsed <- read.csv("./cox-parsed.csv")

# Create train and test datasets
set.seed(1)
index = sample( 1:nrow( compas_non_violent ), round( nrow( compas_non_violent )*0.6 ), replace = FALSE )
train = compas_non_violent[ index, ] # About 60% of the observations
test = compas_non_violent[ -index, ] # About 40% of the observations
```


# LDA Analysis
```{r}
# Check for correlation between input variables
compas.var.names <- c("priors_count", "juv_fel_count", "juv_misd_count", "juv_other_count")
pairs(compas_non_violent[,compas.var.names])
round(cor(compas_non_violent[,compas.var.names]), 3)

# Function to check for correlation 
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = pmax(1, cex.cor * r))
}

# No obvious correlation between any predictors, which is good
pairs(compas_non_violent[,compas.var.names], lower.panel = panel.cor)

# The code below constructs RAIs for predicting two-year recidivism and two-year violent recidivism on the Broward County population using LDA models and the predictors gender_factor, age_factor, race_factor, crime_factor, priors_count, juv_fel_count, juv_misd_count, and juv_other_count. 

# --------------------------------------NONVIOLENT LDA MODEL---------------------------------------------------
nonviolent.lda <- lda(is_recid ~ gender_factor + age_factor + race_factor + crime_factor + priors_count + juv_fel_count + juv_misd_count + juv_other_count, data=train)
nonviolent.lda
nonviolent.lda.train = predict(nonviolent.lda, type="response")
tab <- table(nonviolent.lda.train$class, train$is_recid)
tab

# Training Accuracy for Nonviolent LDA model is 2490/3703 = 67.243% (exact numbers will change after every run, but accuracy will remain approximately the same)

# Test the Nonviolent LDA model
nonviolent.lda.test = predict(nonviolent.lda, newdata=test)
tab <- table(nonviolent.lda.test$class, test$is_recid)
tab

# Test Accuracy for Nonviolent LDA model is 1652/2469 = 66.910% (note that this is less than the training accuracy)

 
# -------------------------------------VIOLENT LDA MODEL----------------------------------------------------------
violent.lda <- lda(is_violent_recid ~ gender_factor + age_factor + race_factor + crime_factor + priors_count + juv_fel_count + juv_misd_count + juv_other_count, data=train)
violent.lda
violent.lda.train = predict(violent.lda, type="response")
tab <- table(violent.lda.train$class, train$is_violent_recid)
tab

# Training Accuracy for Violent LDA model is 3291/3703 = 88.874% (optimistic estimate)

# Test the Violent LDA model
violent.lda.test = predict(violent.lda, newdata=test)
tab <- table(violent.lda.test$class, test$is_violent_recid)
tab

# Test Accuracy for Violent LDA model is 2175/2469 = 88.092% (note that this is less than the training accuracy)

```

# Cox Proportional Hazards LDA
```{r}

# Run a Cox Proportional Hazards model to compare the accuracy of the LDA models to COMPAS' model

# Create new dataframe test_with_labels that appends labels to test dataframe
test_with_labels <- test
test_with_labels$nonviolent_lda_labels = nonviolent.lda.test$class
test_with_labels$violent_lda_labels = violent.lda.test$class

# Write lda predictions to cox-parsed-lda.csv 
cox_parsed_lda = cox_parsed[FALSE,]
for (i in (1: nrow(test_with_labels))) {
  new_rows <- subset(cox_parsed, name == as.character(test_with_labels[i,]$name))
  new_rows$non_violent_lda_labels = test_with_labels[i, ]$nonviolent_lda_labels
  new_rows$violent_lda_labels = test_with_labels[i, ]$violent_lda_labels
  cox_parsed_lda <- rbind(cox_parsed_lda, new_rows)
}


#write.csv(cox_parsed_lda, "cox-parsed-lda.csv")

data <- filter(filter(read.csv("./cox-parsed-lda.csv"), score_text != "N/A"), end > start) %>%
        mutate(race_factor = factor(race,
                                  labels = c("African-American", 
                                             "Asian",
                                             "Caucasian", 
                                             "Hispanic", 
                                             "Native American",
                                             "Other"))) %>%
        within(race_factor <- relevel(race_factor, ref = 3)) %>%
        mutate(score_factor = factor(score_text)) %>%
        within(score_factor <- relevel(score_factor, ref=2)) %>%
        mutate(non_violent_score_factor = factor(non_violent_lda_labels)) %>%
        within(non_violent_score_factor <- relevel(non_violent_score_factor, ref = 1)) %>%
        mutate(violent_score_factor = factor(violent_lda_labels)) %>%
        within(violent_score_factor <- relevel(violent_score_factor, ref = 1))
    

f <- Surv(start, end, event, type="counting") ~ non_violent_score_factor
nonviolent_model <- coxph(f, data=data)
summary(nonviolent_model)
# Nonviolent LDA model has a concordance of 62.3%
# COMPAS system's concordance is 63.6%

f <- Surv(start, end, event, type="counting") ~ violent_score_factor
violent_model <- coxph(f, data=data)
summary(violent_model)
# Violent LDA model has a concordance of 50.2%
# COMPAS's violent recidivism score has a concordance score of 65.1%



```

# QDA Analysis
```{r}

# The code below constructs RAIs for predicting two-year recidivism and two-year violent recidivism on the Broward County population using QDA models and the predictors gender_factor, age_factor, race_factor, crime_factor, priors_count, juv_fel_count, juv_misd_count, and juv_other_count. 

# -------------------------------------------------NONVIOLENT QDA MODEL----------------------------------------------------------
nonviolent.qda <- qda(is_recid ~ gender_factor + age_factor + race_factor + crime_factor + priors_count + juv_fel_count + juv_misd_count + juv_other_count, data=train)
nonviolent.qda
nonviolent.qda.train = predict(nonviolent.qda, type="response")
tab <- table(nonviolent.qda.train$class, train$is_recid)
tab

# Training Accuracy for Nonviolent QDA model is 2298/3703 = 62.058 

# Test the Nonviolent QDA model
nonviolent.qda.test = predict(nonviolent.qda, newdata=test)
tab <- table(nonviolent.qda.test$class, test$is_recid)
tab

# Test Accuracy for Nonviolent QDA model is 1550/2469 = 62.778% 

 
# -----------------------------------------------VIOLENT QDA MODEL------------------------------------------------------------
violent.qda <- qda(is_violent_recid ~ gender_factor + age_factor + race_factor + crime_factor + priors_count + juv_fel_count + juv_misd_count + juv_other_count, data=train)
violent.qda
violent.qda.train = predict(violent.qda, type="response")
tab <- table(violent.qda.train$class, train$is_violent_recid)
tab

# Training Accuracy for Violent QDA model is 3162/3703 = 85.390%

# Test the Violent QDA model
violent.qda.test = predict(violent.qda, newdata=test)
tab <- table(violent.qda.test$class, test$is_violent_recid)
tab

# Test Accuracy for Violent QDA model is 2115/2469 = 85.662%

```

# Cox Proportional Hazards QDA
```{r}

# Run a Cox Proportional Hazards model to compare the accuracy of QDA models to COMPAS' model

# Create new dataframe test_with_labels that appends labels to test dataframe
test_with_labels <- test
test_with_labels$nonviolent_qda_labels = nonviolent.qda.test$class
test_with_labels$violent_qda_labels = violent.qda.test$class

# Write qda predictions to cox-parsed-qda.csv 
cox_parsed_qda = cox_parsed[FALSE,]
for (i in (1: nrow(test_with_labels))) {
  new_rows <- subset(cox_parsed, name == as.character(test_with_labels[i,]$name))
  new_rows$non_violent_qda_labels = test_with_labels[i, ]$nonviolent_qda_labels
  new_rows$violent_qda_labels = test_with_labels[i, ]$violent_qda_labels
  cox_parsed_qda <- rbind(cox_parsed_qda, new_rows)
}


#write.csv(cox_parsed_qda, "cox-parsed-qda.csv")

data <- filter(filter(read.csv("./cox-parsed-qda.csv"), score_text != "N/A"), end > start) %>%
        mutate(race_factor = factor(race,
                                  labels = c("African-American", 
                                             "Asian",
                                             "Caucasian", 
                                             "Hispanic", 
                                             "Native American",
                                             "Other"))) %>%
        within(race_factor <- relevel(race_factor, ref = 3)) %>%
        mutate(score_factor = factor(score_text)) %>%
        within(score_factor <- relevel(score_factor, ref=2)) %>%
        mutate(non_violent_score_factor = factor(non_violent_qda_labels)) %>%
        within(non_violent_score_factor <- relevel(non_violent_score_factor, ref = 1)) %>%
        mutate(violent_score_factor = factor(violent_qda_labels)) %>%
        within(violent_score_factor <- relevel(violent_score_factor, ref = 1))
    

f <- Surv(start, end, event, type="counting") ~ non_violent_score_factor
nonviolent_model <- coxph(f, data=data)
summary(nonviolent_model)
# Nonviolent QDA model has a concordance of 58.9%
# COMPAS system's concordance is 63.6%

f <- Surv(start, end, event, type="counting") ~ violent_score_factor
violent_model <- coxph(f, data=data)
summary(violent_model)
# Violent QDA model has a concordance of 52.7%
# COMPAS's violent recidivism score has a concordance score of 65.1%


```







